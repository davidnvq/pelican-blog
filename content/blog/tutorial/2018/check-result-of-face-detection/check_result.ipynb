{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import os\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get home_path\n",
    "We get `home_path` on different machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/quanguet'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_path = osp.expanduser('~')\n",
    "home_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the IoU\n",
    "We define the function to compute the IoU of a predicted box with a list of ground truth boxes.\n",
    "\n",
    "A box is represented by a list `[xmin, ymin, xmax, ymax]`.\n",
    "\n",
    "A list ground truth boxes is a list of boxes `[box1, box2, box3]`.\n",
    "\n",
    "All are `np.array`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(pred_img_box, gt_img_boxes):\n",
    "    # Compute the area of all boxes including the predicted box\n",
    "    pred_box_area  = (pred_img_box[2] - pred_img_box[0] + 1) # area = w\n",
    "    pred_box_area *= (pred_img_box[3] - pred_img_box[1] + 1) # area = w * h\n",
    "    gt_boxes_area  = (gt_img_boxes[:, 2] - gt_img_boxes[:, 0] + 1)  # area = w\n",
    "    gt_boxes_area *= (gt_img_boxes[:, 3] - gt_img_boxes[:, 1] + 1) # area = w * h\n",
    "\n",
    "    xx1 = np.maximum(pred_img_box[0], gt_img_boxes[:, 0])\n",
    "    yy1 = np.maximum(pred_img_box[1], gt_img_boxes[:, 1])\n",
    "    xx2 = np.minimum(pred_img_box[2], gt_img_boxes[:, 2])\n",
    "    yy2 = np.minimum(pred_img_box[3], gt_img_boxes[:, 3])\n",
    "\n",
    "    # Compute the area of intersection\n",
    "    w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "    h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "\n",
    "    inter = w * h\n",
    "    # get IoU all boxes with the box of highest conf\n",
    "    iou = inter / (pred_box_area + gt_boxes_area[:] - inter)\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check whether a predict box is a ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_box_is_gt_box(pred_img_box, gt_img_boxes, threshold=0.5):\n",
    "    iou = get_iou(pred_img_box, gt_img_boxes)\n",
    "    return np.any(iou > threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the prediction from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = argparse.ArgumentParser().parse_args()\n",
    "\n",
    "result_path = 'Dropbox/DeepFPNResnet/Resnet101/afw_Deepresnet101_val.txt'\n",
    "data_root = 'Datasets/AFW'\n",
    "\n",
    "def get_pred_data():\n",
    "    # file_name score \n",
    "    boxes = {}\n",
    "    scores = {}\n",
    "    img_names = []\n",
    "    img_paths = []\n",
    "\n",
    "    with open(osp.join(home_path, result_path), \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        elems = line.split(\" \")\n",
    "        img_name = elems[0] + '.jpg'\n",
    "        score = float(elems[1])\n",
    "        box = elems[2:]\n",
    "        box = [float(value) for value in box]\n",
    "\n",
    "        if len(img_names) == 0 or img_name != img_names[-1]:\n",
    "            img_names.append(img_name)\n",
    "            img_paths.append(osp.join(home_path, data_root, img_name))\n",
    "\n",
    "        if boxes.get(img_name) is None:\n",
    "            boxes[img_name] = []\n",
    "            scores[img_name] = []\n",
    "        boxes[img_name].append(box)\n",
    "        scores[img_name].append(score)\n",
    "\n",
    "    final_boxes, final_scores = [], []\n",
    "    for img_name in img_names:\n",
    "        final_boxes.append(np.array(boxes[img_name]))\n",
    "        final_scores.append(np.array(scores[img_name]))\n",
    "\n",
    "    return img_names, img_paths, final_boxes, final_scores\n",
    "\n",
    "img_names, img_paths, final_boxes, final_scores = get_pred_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2353849.jpg',\n",
       " '2201628776.jpg',\n",
       " '406798473.jpg',\n",
       " '70037463.jpg',\n",
       " '2030653815.jpg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/quanguet/Datasets/AFW/2353849.jpg',\n",
       " '/Users/quanguet/Datasets/AFW/2201628776.jpg',\n",
       " '/Users/quanguet/Datasets/AFW/406798473.jpg',\n",
       " '/Users/quanguet/Datasets/AFW/70037463.jpg',\n",
       " '/Users/quanguet/Datasets/AFW/2030653815.jpg']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 277. ,  478. ,  471. ,  791.3],\n",
       "        [ 971.3,  444.7, 1115.3,  631.7],\n",
       "        [ 678.7,  894.2,  783.6, 1030.6]]),\n",
       " array([[576. , 338.7, 755.3, 590.7],\n",
       "        [730.1, 103. , 742.1, 119. ],\n",
       "        [719.2, 132.6, 739.8, 156.6]]),\n",
       " array([[517.7, 370.7, 649.3, 545.7],\n",
       "        [312. , 346.3, 446. , 513. ],\n",
       "        [818.3, 375.3, 966.3, 572. ]]),\n",
       " array([[ 470. ,  193.3,  681.3,  517.7],\n",
       "        [1011. ,  406.7, 1259.3,  733.3]]),\n",
       " array([[724.3, 435. , 914. , 681. ],\n",
       "        [529. , 459.8, 636.2, 659.2]])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_boxes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.   , 1.   , 0.998]),\n",
       " array([1.   , 0.883, 0.637]),\n",
       " array([1., 1., 1.]),\n",
       " array([1., 1.]),\n",
       " array([1.   , 0.496])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
